{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYoVrnewenmh"
   },
   "source": [
    "### Bag of words: Solutions\n",
    "\n",
    "\n",
    "- In this Exercise, you are going to classify whether a given movie review is **positive or negative**.\n",
    "- you are going to use Bag of words for pre-processing the text and apply different classification algorithms.\n",
    "- Sklearn CountVectorizer has the inbuilt implementations for Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JW6MPIjib_4G"
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from  sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDATDCL8NMML"
   },
   "source": [
    "### **About Data: IMDB Dataset**\n",
    "\n",
    "Credits: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?resource=download\n",
    "\n",
    "\n",
    "- This data consists of two columns.\n",
    "        - review\n",
    "        - sentiment\n",
    "- Reviews are the statements given by users after watching the movie.\n",
    "- sentiment feature tells whether the given review is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "beL29JwEb_7O",
    "outputId": "cf0a9e1e-b80b-4447-d759-0828baba2620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I first saw Jake Gyllenhaal in Jarhead (2005) ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I enjoyed the movie and the story immensely! I...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had a hard time sitting through this. Every ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's hard to imagine that anyone could find th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is one military drama I like a lot! Tom B...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I first saw Jake Gyllenhaal in Jarhead (2005) ...  positive\n",
       "1  I enjoyed the movie and the story immensely! I...  positive\n",
       "2  I had a hard time sitting through this. Every ...  negative\n",
       "3  It's hard to imagine that anyone could find th...  negative\n",
       "4  This is one military drama I like a lot! Tom B...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. read the data provided in the same directory with name 'movies_sentiment_data.csv' and store it in df variable\n",
    "df = pd.read_csv(\"movies_sentiment_data.csv\")\n",
    "\n",
    "\n",
    "#2. print the shape of the data\n",
    "print(df.shape)\n",
    "\n",
    "#3. print top 5 datapoints\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new column \"Category\" which represent 1 if the sentiment is positive or 0 if it is negative\n",
    "df['Category'] = df['sentiment'].apply(lambda x: 1 if x =='positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSwPM7mub_9S",
    "outputId": "2b68719c-b7f4-48b8-a41e-3f95cca9f2f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "1    9500\n",
       "0    9500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of 'Category' and see whether the Target labels are balanced or not.\n",
    "\n",
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IB97QiFCcAAe"
   },
   "outputs": [],
   "source": [
    "#Do the 'train-test' splitting with test size of 20%\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.review, df.Category, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtr4mSLEMWiU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-pUGPqwMrDQ"
   },
   "source": [
    "**Exercise-1**\n",
    "\n",
    "1. using sklearn pipeline module create a classification pipeline to classify the movie review's positive or negative.\n",
    "\n",
    "**Note:**\n",
    "- use CountVectorizer for pre-processing the text.\n",
    "\n",
    "- use **Random Forest** as the classifier with estimators as 50 and criterion as entropy.\n",
    "- print the classification report.\n",
    "\n",
    "**References**:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CbldZv03MWkB",
    "outputId": "cf70d361-da12-46a9-8d59-73cdba9bad91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1910\n",
      "           1       0.83      0.82      0.82      1890\n",
      "\n",
      "    accuracy                           0.83      3800\n",
      "   macro avg       0.83      0.83      0.83      3800\n",
      "weighted avg       0.83      0.83      0.83      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),                                                    #initializing the vectorizer\n",
    "    ('random_forest', (RandomForestClassifier(n_estimators=50, criterion='entropy')))      #using the RandomForest classifier\n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\"I first saw Jake Gyllenhaal in Jarhead (2005) a little while back and, since then, I've been watching every one of his movies that arrives on my radar screen. Like Clive Owen, he has an intensity (and he even resembles Owen somewhat) that just oozes from the screen. I feel sure that, if he lands some meaty roles, he'll crack an Oscar one day...<br /><br />That's not to denigrate this film at all.<br /><br />It's a fine story, with very believable people (well, it's based upon the author's early shenanigans with rocketry), a great cast  Chris Cooper is always good, and Laura Dern is always on my watch list  with the appropriate mix of humor, pathos, excitement...and the great sound track with so many rock n roll oldies to get the feet tapping.<br /><br />But, this film had a very special significance for me: in 1957, I was the same age as Homer Hickham; like him, I looked up at the night stars to watch Sputnik as it scudded across the blackness; like Homer also, I experimented with rocketry in my backyard and used even the exact same chemicals for fuel; and like Homer, I also had most of my attempts end in explosive disaster! What fun it was...<br /><br />I didn't achieve his great (metaphorical and physical) heights though. But, that's what you find out when you see this movie.<br /><br />Sure, it's a basic family movie, but that's a dying breed these days, it seems. Take the time to see it, with the kids: you'll all have a lot of good laughs.\",\n",
    "\"I enjoyed the movie and the story immensely! I have seen the original(1939 I believe) and enjoyed them both. To really appreciate the story one must be familiar with English culture and customs. The prof.(Peter O'Toole) was dedicated to his school and \"\"the boys\"\" in that school. It was an English \"\"public\"\" school, which we in the U.S. refer to as a private school (E.G. Andover). He is a very ascetic person and, on the surface, gives the appearance of being stiff, stuffy, uncaring, and weak to the point of being effeminate. He is strict in his educational standards because he DOES care for \"\"his lads\"\", i.e., he doesn't want them to get a cheap or weak education. He meets(through introduction) a \"\"dance hall girl\"\"(Petula Clark) and is totally smitten. In England at the time, the reference to \"\"dance hall\"\" carried the connotation of extreme sexual promiscuity and was definitely \"\"lower class\"\". We find that the Prof. is in fact a very tough and courageous person as well as loyal to people and institutions that he loves and/or respects. Clark becomes more than a lover and wife...she \"\"leavens\"\" his personality and allows him to grow as a man and a person, much to the benefit of his beloved school and his own happiness. The first movie was set BEFORE WW II, this one goes through WW II, also, it is 1969( we've had the \"\"British Invasion\"\"...Beetles, etc. Clark had hits and was very popular then...still is to me), the music is great, color and photography excellent. I think O'Toole played the character perfectly! There ARE dedicated people like \"\"Chips\"\"...all around us but many do not receive the recognition. Very enjoyable movie and story!\",\n",
    "\"I had a hard time sitting through this. Every single twist and turn is predictable. You're sitting there just waiting for it ... waiting for it ... and yes, there it is! Just as you predicted at the very beginning of the movie. Or 10 minutes out. Et cetera. <br /><br />Smart writing? No. <br /><br />Torture porn? No, there's no nudity. Other reviews calling this torture porn are most likely written by people on heavy drugs. Unfortunately there's no torture and no nudity (yes, no nudity).<br /><br />There's no suspense at all in this \"\"thriller\"\". The only good part about this movie is the ending, but I'm not going to spoil that.<br /><br />I'm giving it a 2/10. A 1/10 would be a horrible B-movie. This movie had better acting.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions for new data\n",
    "predictions = clf.predict(reviews)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see above, for both the classes (positive and negative sentiment) we got more than 80% precision, recall and f1- score. This seems to be an acceptable performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMVvGzqXSFYr"
   },
   "source": [
    "**Exercise-2**\n",
    "\n",
    "1. using sklearn pipeline module create a classification pipeline to classify the movie review's positive or negative..\n",
    "\n",
    "**Note:**\n",
    "- use CountVectorizer for pre-processing the text.\n",
    "- use **KNN** as the classifier with n_neighbors of 10 and metric as 'euclidean'.\n",
    "- print the classification report.\n",
    "\n",
    "**References**:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tYkY77S6MWng",
    "outputId": "53275bdc-4629-464c-d26f-00075b080174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.64      1849\n",
      "           1       0.66      0.64      0.65      1951\n",
      "\n",
      "    accuracy                           0.65      3800\n",
      "   macro avg       0.65      0.65      0.65      3800\n",
      "weighted avg       0.65      0.65      0.65      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "                \n",
    "     ('vectorizer', CountVectorizer()),   \n",
    "      ('KNN', (KNeighborsClassifier(n_neighbors=10, metric = 'euclidean')))   #using the KNN classifier with 10 neighbors \n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hmmm..here the performance of various metrics (precision, recall etc.) seem to be lower (~60 %). Let's try one more classifier and then discuss why performance is varying so much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-3**\n",
    "\n",
    "1. using sklearn pipeline module create a classification pipeline to classify the movie review's positive or negative..\n",
    "\n",
    "**Note:**\n",
    "- use CountVectorizer for pre-processing the text.\n",
    "- use **Multinomial Naive Bayes** as the classifier.\n",
    "- print the classification report.\n",
    "\n",
    "**References**:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85      1849\n",
      "           1       0.88      0.82      0.85      1951\n",
      "\n",
      "    accuracy                           0.85      3800\n",
      "   macro avg       0.85      0.85      0.85      3800\n",
      "weighted avg       0.85      0.85      0.85      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "                \n",
    "     ('vectorizer', CountVectorizer()),   \n",
    "      ('Multi NB', MultinomialNB())   #using the Multinomial Naive Bayes classifier \n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- That's great! MultinomialNB model for both the classes (positive and negative sentiment) we got more than 80% precision, recall and f1- score and performed equally good with Random Forest. This seems to be an acceptable performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you write some observations of why model like KNN fails to produce good results unlike RandomForest and MultinomialNB?\n",
    "\n",
    "- As Machine learning algorithms does not work on Text data directly, we need to convert them into numeric vector and feed that into models while training.\n",
    "- In this process, we convert text into a very **high dimensional numeric vector** using the technique of Bag of words.\n",
    "- Model like K-Nearest Neighbours(KNN) doesn't work well with high dimensional data because with large number of dimensions, it becomes difficult for the algorithm to calculate distance in each dimension. In higher dimensional space, the cost to calculate distance becomes expensive and hence impacts the performance of model.\n",
    "- The easy calculation of probabilities for the words in corpus(Bag of words) and storing them in contigency table is the major reason for the Multinomial NaiveBayes to be a text classification friendly algorithm.\n",
    "- As Random Forest uses Bootstrapping(Row and column Sampling) with many decision tree and overcomes the high variance and overfitting of high dimensional data and also uses feature importance of words for better classifing the categories.\n",
    "- Machine Learning is like trial and error scientific method, where we keep trying all the possible algorithms we have and select the one which give good results and satisfy the requirements like latency, interpretability etc.\n",
    "\n",
    "Refer these resources to get good idea:\n",
    "- https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/\n",
    "- https://analyticsindiamag.com/naive-bayes-why-is-it-favoured-for-text-related-tasks/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BOW_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "testingP10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
